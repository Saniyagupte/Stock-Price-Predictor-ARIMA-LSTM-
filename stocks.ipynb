import pandas as pd

# Load the 'prices-split-adjusted.csv' and 'fundamentals.csv' files from the NYE stocks dataset.
# These datasets are being merged to provide a comprehensive view of AAPL (Apple Inc.) for analysis.
try:
    df_prices = pd.read_csv('prices-split-adjusted.csv')  # Load stock price data with adjusted splits
    df_fundamentals = pd.read_csv('fundamentals.csv')  # Load financial data for AAPL from the dataset
except FileNotFoundError:
    print("Error: One or both of the CSV files were not found. Please ensure they are in the correct directory.")
    exit()

# Filter the prices dataset to include only AAPL (Apple Inc.) stock data for analysis.
df_prices_aapl = df_prices[df_prices['symbol'] == 'AAPL'].copy()

# Convert the 'date' column from string to datetime format to facilitate time series operations.
df_prices_aapl['date'] = pd.to_datetime(df_prices_aapl['date'])

# Filter the fundamentals dataset to retain only the data relevant to AAPL.
df_fundamentals_aapl = df_fundamentals[df_fundamentals['Ticker Symbol'] == 'AAPL'].copy()

# Convert the 'Period Ending' column to datetime format and extract the year for aligning with price data.
df_fundamentals_aapl['Period Ending'] = pd.to_datetime(df_fundamentals_aapl['Period Ending'])
df_fundamentals_aapl['Year'] = df_fundamentals_aapl['Period Ending'].dt.year

# Extract the year from the 'date' column in the price data to align with the fundamental data for merging.
df_prices_aapl['Year'] = df_prices_aapl['date'].dt.year

# Merge the two dataframes (price and fundamental) on the 'Year' column, keeping only rows with matching years.
merged_df = pd.merge(df_prices_aapl, df_fundamentals_aapl, on='Year', how='inner')

# Save the merged dataframe into a new CSV file for subsequent analysis and modeling.
merged_df.to_csv('AAPL_combined_data.csv', index=False)

# Inform the user that the data has been successfully merged and saved.
print("Combined data for AAPL has been saved to 'AAPL_combined_data.csv'")

# Display the column names of the merged dataframe to verify the structure and data available.
print("\nColumns in the merged DataFrame:")
print(merged_df.columns.tolist())

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from statsmodels.tsa.arima.model import ARIMA
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import numpy as np
import matplotlib.pyplot as plt

# Load the combined AAPL data from the CSV file generated in the previous step.
try:
    df = pd.read_csv('AAPL_combined_data.csv')
except FileNotFoundError:
    print("Error: 'AAPL_combined_data.csv' not found. Please run the previous steps first.")
    exit()

# Sort the data by 'date' to ensure it is in chronological order for time series analysis.
df['date'] = pd.to_datetime(df['date'])
df = df.sort_values('date')

# Set the 'date' column as the index of the dataframe for easier handling of time series data.
df = df.set_index('date')

# Extract the 'close' price from the dataframe as the target variable for prediction.
data = df['close'].values.reshape(-1, 1)

# Normalize the 'close' price data using Min-Max scaling to improve model convergence during training.
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)

# Split the scaled data into training (80%) and testing (20%) sets for model evaluation.
train_size = int(len(scaled_data) * 0.8)
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size:]

# --- ARIMA Model Section ---
# ARIMA (AutoRegressive Integrated Moving Average) is applied to model the time series and forecast future values.

# Define the ARIMA model parameters (p, d, q), which can be tuned based on the dataset's characteristics.
arima_order = (5, 1, 0)  # Example values, adjustment of the order may be required for optimal performance.

# Fit the ARIMA model on the training data to capture trends and patterns in the time series.
arima_model = ARIMA(train_data, order=arima_order)
arima_fit = arima_model.fit()

# Extract the residuals (errors) from the ARIMA model, which will be predicted by the LSTM model later.
arima_residuals = arima_fit.resid.reshape(-1, 1)

# Scale the residuals using Min-Max scaling to prepare them for input into the LSTM model.
residual_scaler = MinMaxScaler()
scaled_residuals = residual_scaler.fit_transform(arima_residuals)

# --- LSTM Model Section ---
# LSTM (Long Short-Term Memory) networks are used to model sequential data and learn from ARIMA residuals.

# Define a function to create sequences of data for training the LSTM model. Each sequence predicts the next residual.
def create_sequences(data, seq_length):
    sequences = []
    targets = []
    for i in range(len(data) - seq_length):
        seq = data[i:i + seq_length]
        target = data[i + seq_length]
        sequences.append(seq)
        targets.append(target)
    return np.array(sequences), np.array(targets)

# Set the sequence length to 30, meaning the LSTM will learn from the past 30 residuals to predict the next one.
seq_length = 30
X_train_res, y_train_res = create_sequences(scaled_residuals, seq_length)

# Reshape the input data into a 3D array with shape (samples, time steps, features) for LSTM input.
X_train_res = np.reshape(X_train_res, (X_train_res.shape[0], X_train_res.shape[1], 1))

# Build the LSTM model with two layers of LSTM units and a Dense layer to output a prediction.
lstm_model = Sequential()
lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(seq_length, 1)))
lstm_model.add(LSTM(units=50))
lstm_model.add(Dense(units=1))
lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the LSTM model on the residual data for 50 epochs.
lstm_model.fit(X_train_res, y_train_res, epochs=50, batch_size=32, verbose=0)

# --- Combined Forecasting Section ---
# This section generates predictions for future stock prices by combining ARIMA forecasts with LSTM residual predictions.

# Initialize the history with the training data and prepare to predict the next 252 business days (1 year).
history = list(train_data.flatten())
future_predictions = []

for _ in range(252):
    # 1. ARIMA Prediction: Forecast the next value using the ARIMA model.
    arima_model_iter = ARIMA(history, order=arima_order)
    arima_fit_iter = arima_model_iter.fit()
    arima_forecast_scaled = arima_fit_iter.forecast(steps=1)[0]

    # 2. LSTM Residual Prediction: Predict the next residual using the trained LSTM model.
    last_residual_sequence_scaled = scaled_residuals[-seq_length:].reshape(1, seq_length, 1)
    lstm_residual_scaled = lstm_model.predict(last_residual_sequence_scaled)[0, 0]
    lstm_residual = residual_scaler.inverse_transform(np.array([[lstm_residual_scaled]]))[0, 0]

    # 3. Combine the ARIMA forecast and LSTM residual to obtain the final forecasted stock price.
    combined_forecast_scaled = arima_forecast_scaled + lstm_residual
    combined_forecast = scaler.inverse_transform(np.array([[combined_forecast_scaled]]))[0, 0]

    # Append the combined forecast to the future predictions list.
    future_predictions.append(combined_forecast)

    # Update the history with the new prediction for the next iteration.
    history.append(scaler.transform(np.array([[combined_forecast]]))[0, 0])
    scaled_residuals = np.append(scaled_residuals, [[lstm_residual_scaled]], axis=0)  # Update residuals

# Generate future dates corresponding to the forecasted stock prices.
last_date = df.index[-1]
future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=252, freq='B')
future_df = pd.DataFrame({'Predicted Price': future_predictions}, index=future_dates)

# --- Visualization Section ---
# Plot the historical closing prices and the predicted stock prices for the next year using ARIMA and LSTM.

plt.figure(figsize=(12, 6))
plt.plot(df['close'], label='Historical Closing Price')  # Plot historical stock prices
plt.plot(future_df.index, future_df['Predicted Price'], label='ARIMA-LSTM Predicted Price (Next Year)', color='red')  # Plot predicted prices
plt.title('AAPL Stock Price Prediction (ARIMA-LSTM)')
plt.xlabel('Date')
plt.ylabel('Closing Price')
plt.legend()
plt.grid(True)

# Save the plot as a PNG file for future reference.
plt.savefig('AAPL_stock_price_prediction_arima_lstm.png')
plt.show()

# Inform the user that the plot has been successfully generated and saved.
print("\nPlotting the historical and ARIMA-LSTM predicted stock prices for the next year.")
print("The red line shows the combined prediction.")
print("The plot has been saved as 'AAPL_stock_price_prediction_arima_lstm.png'.")

# --- Model Evaluation Section ---
# Calculate and display model evaluation metrics (MSE, RMSE, MAE, MAPE) for the forecasted data.

from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error

# Assuming we have actual prices for the test set to compare predictions (replace 'actual_prices' with the actual test data).
mse = mean_squared_error(actual_prices, future_predictions)  # Mean Squared Error
rmse = np.sqrt(mse)  # Root Mean Squared Error
mae = mean_absolute_error(actual_prices, future_predictions)  # Mean Absolute Error
mape = mean_absolute_percentage_error(actual_prices, future_predictions)  # Mean Absolute Percentage Error

# Print the evaluation metrics for model performance.
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")
